{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPVNapbNmH+HvRsXmFxk9KM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Iispar/review-summary-API/blob/main/BERT-finetuned-model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BGsadXKMQ8Oc"
      },
      "outputs": [],
      "source": [
        "!pip3 install -q transformers datasets evaluate\n",
        "!pip install optuna\n",
        "import datasets\n",
        "import numpy as np\n",
        "import transformers\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import DataCollatorWithPadding\n",
        "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "import evaluate\n",
        "import optuna"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = 'distilbert-base-cased'\n",
        "dset = 'mteb/amazon_reviews_multi'"
      ],
      "metadata": {
        "id": "bifgE2WQhyqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing\n",
        "\n",
        "The dataset includes reviews from multiple languages so we only import the english ones. The dataset also includes alot of useless data for us, we only need the reviews and their ratings so lets process everything else out."
      ],
      "metadata": {
        "id": "R9BAgEVnxgtg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = datasets.load_dataset(dset, name='en'); # imports the dataset.\n",
        "# check it works\n",
        "print(dataset);"
      ],
      "metadata": {
        "id": "EYTMXhkfRACQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "engDataset = datasets.load_dataset(dset, name='en'); # imports the dataset.\n",
        "# check it works\n",
        "print(engDataset);\n",
        "\n",
        "# FOR TESTING make the dataset smaller\n",
        "# engDataset[\"train\"] = engDataset[\"train\"].select(range(100000))"
      ],
      "metadata": {
        "id": "7IExB3RqRBTf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "engDataset = engDataset.shuffle() # shuffle the dataset for safety.\n",
        "engDataset = engDataset.remove_columns(['id', 'label_text']) # removes everything that we don't need"
      ],
      "metadata": {
        "id": "pFaB-khJeq0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenization and padding"
      ],
      "metadata": {
        "id": "3ouhPfMwyAH-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = DistilBertTokenizer.from_pretrained(model) # get the basic AutoTokenizer\n",
        "# Used the BertTokenizer instead of AutoTokenizer, because we want the token type ids to be used for BERT."
      ],
      "metadata": {
        "id": "WfJcULS9RCz1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenizes one example\n",
        "def tokenize_example(example):\n",
        "    split = example['text'].split('\\n\\n'); # splits the sentace and title.\n",
        "    return tokenizer.encode_plus(split[0], split[1], # input title and body seperately\n",
        "             truncation='only_second', # only cut the second, which is the actual body of the review\n",
        "             add_special_tokens=True, # add CLS and SEP\n",
        "             max_length=512, # max len is same as BERTs\n",
        "             padding='max_length') # pad to max length"
      ],
      "metadata": {
        "id": "tSBOZ-ByRHM_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# map the whole dset\n",
        "eng_tokenized = engDataset.map(tokenize_example)"
      ],
      "metadata": {
        "id": "SE_HOOUdRIzM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(eng_tokenized['train'][1])\n",
        "print(tokenizer.decode(eng_tokenized['train'][1]['input_ids']))\n",
        "\n",
        "# looks good to me."
      ],
      "metadata": {
        "id": "Ss-8nLDbe4UB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine tuning the BERT model for our classification"
      ],
      "metadata": {
        "id": "NTzrN56KyXf0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# config\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Create the bert class\n",
        "class Bert(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Bert, self).__init__()\n",
        "        # hidden size of BERT (always 768), hidden size of our classifier, and number of labels (in this case 5)\n",
        "        H_in, H, labels = 768, 25, 5\n",
        "\n",
        "        # bert is our preloaded distilbert\n",
        "        self.bert = DistilBertModel.from_pretrained(model)\n",
        "\n",
        "        # basic one layer feed forward network that outputs the labels.\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(H_in, H), # bert in.\n",
        "            nn.ReLU(), # ReLU\n",
        "            #nn.Dropout(0.5), #dropout if needed.\n",
        "            nn.Linear(H, labels) # to output labels\n",
        "        )\n",
        "    def forward(self, input_ids, attention_mask, labels=None):\n",
        "\n",
        "        # run the BERT\n",
        "        outputs = self.bert(input_ids=input_ids,\n",
        "                            attention_mask=attention_mask)\n",
        "\n",
        "        # Extract the last hidden state of the token for classification\n",
        "        last_hidden_state = outputs[0][:, 0, :]\n",
        "\n",
        "        # Feed tha last hidden state into the classifier. This outputs the labels.\n",
        "        logits = self.classifier(last_hidden_state)\n",
        "\n",
        "        # if there is labels so training\n",
        "        if labels is not None:\n",
        "          # calculates the loss.\n",
        "          loss = torch.nn.CrossEntropyLoss();\n",
        "          return (loss(logits,labels),logits);\n",
        "        else:\n",
        "          # if no labels, just return the logits\n",
        "          return (logits,);"
      ],
      "metadata": {
        "id": "ZCeUJiPu4tM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculates the accuracy\n",
        "accuracy = evaluate.load('accuracy');\n",
        "def compute_accuracy(outputs_and_labels):\n",
        "    outputs, labels = outputs_and_labels;\n",
        "    predictions = np.argmax(outputs, axis=-1); #pick the index of the \"winning\" label\n",
        "    return accuracy.compute(predictions=predictions, references=labels); # calc accuracy"
      ],
      "metadata": {
        "id": "QmVLPXyve9QC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Bert() # init the model"
      ],
      "metadata": {
        "id": "xqaDh6lhe-b8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Because the bert is really large lets freeze its weights that we dont want to change.\n",
        "# thisway we can get the model to train a bit faster and inside colab.\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        "    if name.startswith('bert'):\n",
        "        param.requires_grad = False"
      ],
      "metadata": {
        "id": "z_m3lOcbfAef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training params. We optimize these later.\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    evaluation_strategy = 'steps',\n",
        "    logging_strategy = 'steps',\n",
        "    eval_steps = 500,\n",
        "    logging_steps = 500,\n",
        "    learning_rate=1e-4,\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=32,\n",
        "    max_steps = 20000,\n",
        "    num_train_epochs=5,\n",
        "    weight_decay=0.01,\n",
        "  )\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer) # get the data collator with our tokenizer.\n",
        "early_stopping = transformers.EarlyStoppingCallback(3); # stop training if the eval loss is not getting better.\n",
        "\n",
        "# Set the trainer\n",
        "trainer = Trainer(\n",
        "    model = model,\n",
        "    args = training_args,\n",
        "    train_dataset = eng_tokenized['train'],\n",
        "    eval_dataset = eng_tokenized['test'],\n",
        "    tokenizer = tokenizer,\n",
        "    data_collator = data_collator,\n",
        "    compute_metrics = compute_accuracy,\n",
        ")\n",
        "\n",
        "# train the model\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "T2NX0VjHfB4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparam optimization\n",
        "\n",
        "This happens over a couple of days so you won't see all the results..."
      ],
      "metadata": {
        "id": "tw75c9EW4jLN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Used optuna for optimization\n",
        "\n",
        "def objective(trial):\n",
        "    # Define the search space for hyperparameters\n",
        "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-7, 1e-3, log=True)\n",
        "    batch_size = trial.suggest_categorical(\"batch_size\", [8, 4, 16])\n",
        "    epochs=trial.suggest_int('num_train_epochs', low = 2,high = 6),\n",
        "\n",
        "    # params\n",
        "    trainer_args = transformers.TrainingArguments(\n",
        "        \"mlp_checkpoints\",\n",
        "        evaluation_strategy = \"steps\",\n",
        "        logging_strategy = \"steps\",\n",
        "        eval_steps = 500,\n",
        "        logging_steps = 500,\n",
        "        learning_rate = learning_rate,\n",
        "        max_steps = 20000,\n",
        "        load_best_model_at_end = True,\n",
        "        per_device_train_batch_size = batch_size,\n",
        "        per_device_eval_batch_size = batch_size,\n",
        "        num_train_epochs = epochs\n",
        "    )\n",
        "\n",
        "    # the model\n",
        "    mlp = model\n",
        "    early_stopping = transformers.EarlyStoppingCallback(3); # stop training if the eval loss is not getting better.\n",
        "\n",
        "    # train a model\n",
        "    trainer = transformers.Trainer(\n",
        "        model = mlp,\n",
        "        args = trainer_args,\n",
        "        train_dataset = eng_tokenized['train'],\n",
        "        eval_dataset = eng_tokenized['test'],\n",
        "        compute_metrics = compute_accuracy,\n",
        "        data_collator = data_collator,\n",
        "        callbacks = [early_stopping]\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "    eval_results = trainer.evaluate()\n",
        "    return eval_results[\"eval_accuracy\"] # return the best result.\n",
        "\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=20)"
      ],
      "metadata": {
        "id": "kUoYZWf04p_K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}